import { ArticleLayout } from '@/components/ArticleLayout'
import designSystem from './planetaria-design-system.png'

export const article = {
  author: 'Daniel Furman',
  date: '2024-02-01',
  title: 'Evaluating LLMs with Chat Templates',
  description:
    'LLM chatbots are typically finetuned on chat templated datasets. These templates convert conversations into a string, ready for text generation. Matching this format is standard at prediction time, as deviations are oft-noted to hurt performance. This blog explores whether such degradations appear when measuring model performance in evaluation benchmarks.',
}

export const metadata = {
  title: article.title,
  description: article.description,
}

export default (props) => <ArticleLayout article={article} {...props} />

Chat models are typically fine-tuned on datasets formatted with a prompt template. 
These chat templates are programmed recipes that convert a chat conversation into a single string. 
At prediction time, it’s standard to match an LLM’s expected chat format – not doing so is oft-noted as causing performance degradations. 
However, do we in fact see these degradations on evaluation benchmarks?

Read more at https://huggingface.co/blog/dfurman/evaluations-with-chat-formats