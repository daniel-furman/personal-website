import { ArticleLayout } from '@/components/ArticleLayout'
import designSystem from './planetaria-design-system.png'

export const article = {
  author: 'Daniel Furman',
  date: '2024-02-01',
  title: 'Evaluating LLMs with Chat Templates',
  description:
    'LLMs are typically finetuned on chat-templated datasets, which convert conversations into strings ready for text generation. Matching this format is standard at prediction time, as deviations are often noted to hurt performance. Here, we test this theory using an instruction-following benchmark and the best open-source LLMs available.',
}

export const metadata = {
  title: article.title,
  description: article.description,
}

export default (props) => <ArticleLayout article={article} {...props} />

Chat models are typically fine-tuned on datasets formatted with a prompt template. 
These chat templates are programmed recipes that convert a chat conversation into a single string. 
At prediction time, it’s standard to match an LLM’s expected chat format – not doing so is oft-noted as causing performance degradations. 
However, do we in fact see these degradations on evaluation benchmarks?

Read more at https://huggingface.co/blog/dfurman/evaluations-with-chat-formats